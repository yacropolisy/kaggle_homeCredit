{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter tuned\n",
    "reference : https://www.kaggle.com/znyksh/fork-lightgbm-with-simple-features/versions#base=4143658&new=4153250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.07359218597412"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "df = pd.read_csv('./new_feature_by_kageyama_feature_matrix_noIDs.csv')\n",
    "time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('SK_ID_CURR', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:43<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "categorical_feats = [f for f in df.columns if df[f].dtype == 'object']\n",
    "for col in tqdm(categorical_feats):\n",
    "    if col == 'set' :\n",
    "        continue\n",
    "    df[col] = df[col].astype('str')\n",
    "    le.fit(df[col])\n",
    "    df[col] = le.transform(df[col])\n",
    "train_df = df.loc[df['set'] == 'train'] .drop('set', axis = 1)\n",
    "test_df = df.loc[df['set'] == 'test'] .drop(['set', 'TARGET'], axis=1)\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.758766\tvalid_1's auc: 0.751971\n",
      "[200]\ttraining's auc: 0.780869\tvalid_1's auc: 0.764686\n",
      "[300]\ttraining's auc: 0.79807\tvalid_1's auc: 0.774438\n",
      "[400]\ttraining's auc: 0.809729\tvalid_1's auc: 0.779476\n",
      "[500]\ttraining's auc: 0.818902\tvalid_1's auc: 0.782489\n",
      "[600]\ttraining's auc: 0.826994\tvalid_1's auc: 0.783755\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "y = train_df['TARGET'].copy()\n",
    "X = train_df.drop('TARGET', axis = 1)\n",
    "\n",
    "\n",
    "feats =  list(X.columns)\n",
    "\n",
    "folds = KFold(n_splits=25, shuffle=True, random_state=2018)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n",
    "    train_X, train_y = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    valid_X, valid_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=4000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        colsample_bytree=.8,\n",
    "        subsample=.87,\n",
    "        max_depth=8,\n",
    "        reg_alpha=.0415,\n",
    "        reg_lambda=.0735,\n",
    "        min_split_gain=.02,\n",
    "        min_child_weight=40,\n",
    "        silent=-1,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    clf.fit(train_X, train_y, \n",
    "            eval_set= [(train_X, train_y), (valid_X, valid_y)], \n",
    "            eval_metric='auc', verbose=100, early_stopping_rounds=100  #30\n",
    "           )\n",
    "\n",
    "    oof_preds[val_idx] = clf.predict_proba(valid_X, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    sub_preds += clf.predict_proba(test_df, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[val_idx])))\n",
    "    del clf, train_X, train_y, valid_X, valid_y\n",
    "    gc.collect()\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n",
    "\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['TARGET'] = sub_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./kageyama_feature_matrix_25cv_tuned_by_Ivan_sub_noIDs.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "def display_importances(feature_importance_df_):\n",
    "    # Plot feature importances\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "        by=\"importance\", ascending=False)[:50].index\n",
    "    \n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    \n",
    "    plt.figure(figsize=(8,10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", \n",
    "                data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_importances(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n",
    "\n",
    "def norm_feature_importances(df, threshold = 0.95):\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n",
    "    \n",
    "    importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n",
    "    print('%d features required for %0.2f of cumulative importance' % (importance_index + 1, threshold))\n",
    "    \n",
    "    return df\n",
    "\n",
    "norm_feature_importances = norm_feature_importances(feature_importances)\n",
    "\n",
    "df = pd.read_csv('./new_feature_by_kageyama_feature_matrix_noIDs.csv')\n",
    "# Threshold for cumulative importance\n",
    "for threshold in [0.98, 0.96, 0.94, 0.92, 0.9]:\n",
    "\n",
    "    # Extract the features to keep\n",
    "    unimportant_features = list(norm_feature_importances[norm_feature_importances['cumulative_importance'] >= threshold]['feature'])    \n",
    "    df.drop(unimportant_features, axis=1).to_csv('./kageyama_feature_matrix_{}.csv'.format(threshold * 100),  index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
